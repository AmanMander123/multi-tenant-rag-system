project_name: "LLM Multi-Tenant RAG System"
api_v1_prefix: "/api/v1"
celery:
  broker_url: "memory://"
  result_backend: "cache+memory://"
  task_default_queue: "ingestion"
  task_default_routing_key: "ingestion.default"
processing:
  chunk_size: 1000
  chunk_overlap: 200
  embedding_provider: "openai"
  embedding_model: "text-embedding-3-small"
retrieval:
  dense_top_n: 20
  bm25_top_m: 20
  rerank_top_k: 8
  reranker_model: "gpt-4o-mini"
  reranker_provider: "openai"
  reranker_timeout_seconds: 10
  chunk_schema_version: "2024-09-24"
  tsvector_config: "english"
reindex:
  batch_size: 25
  max_documents: 200
  drift_lookback_days: 1
  stale_after_days: 30
  max_attempts: 3
  queue_poll_limit: 200
  soft_timeout_seconds: 600
gcp_project_id: "virtual-assistant-460209"
openai_secret_name: "openai-api-key"
openai_secret_version: "latest"
pubsub_topic_ingest: "projects/virtual-assistant-460209/topics/ingestion-documents"
gcs_upload_bucket: "va-rag-uploads-prod"
default_tenant_id: "default"
supabase_url: "https://virtualassistant460209.supabase.co"
supabase_jwks_url: "https://virtualassistant460209.supabase.co/auth/v1/jwks"
supabase_jwt_audience: "auth.virtualassistant460209.supabase.co"
supabase_auth_required: false
pinecone_index_name: "rag-embeddings-prod-gcp-1a"
pinecone_cloud: "aws"
pinecone_region: "us-east-1"
pinecone_dimension: 1536
firestore_collection_namespace: "tenants"
